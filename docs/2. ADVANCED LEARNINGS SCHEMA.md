# 2. Advanced Learnings Schema

## Overview

This document describes the migration from the basic learning extraction schema to an advanced epistemic introspection framework. The new schema captures not just **what** was learned, but **how well** it's understood, **why** it's true, and **how it felt** to learn it.

This is a **fundamental rearchitecture** of the learning extraction system, replacing simple title/content capture with a rich multi-dimensional learning framework inspired by metacognitive research and intellectual honesty principles.

## Motivation

### Limitations of Current Schema

The current implementation (docs/1. LEARNINGS.md) captures learnings as:
```typescript
interface Learning {
  learningId: string;
  title: string;
  content: string;
  createdAt: Date;
  categories: Category[];
  sources: LearningSource[];
}
```

**Problems:**
1. **No abstraction levels**: Can't distinguish specific examples from general principles
2. **No metacognition**: No sense of confidence or understanding depth
3. **No learning type**: Can't filter for anti-patterns vs. principles vs. methods
4. **Monolithic content**: Title + content blob without structure
5. **Over-engineered categories**: Many-to-many relationships for simple tagging

### New Approach: Epistemic Introspection

The advanced schema asks:
- **What triggered this?** (context)
- **What did I learn?** (insight)
- **Why is this true?** (mechanism)
- **How do I apply it?** (implications)
- **What level is this?** (concrete → pattern → principle)
- **How well do I understand it?** (confidence, gaps)
- **How hard was it?** (cognitive load)
- **How much did it matter?** (emotional resonance)

## High-Level Schema Structure

```typescript
interface Learning {
  // Core learning capture
  title: string;                    // Scannable summary
  context: string;                  // What triggered this exploration
  insight: string;                  // What was discovered
  why: string;                      // Explanation of WHY this is true
  implications: string;             // When/how to apply this
  tags: string[];                   // Free-form tagging for retrieval

  // Abstraction ladder
  abstraction: {
    concrete: string;               // Specific instance
    pattern: string;                // Generalizable pattern
    principle?: string;             // Universal principle (optional)
  };

  // Metacognitive assessment
  understanding: {
    confidence: number;             // 1-10: How well you understand
    can_teach_it: boolean;          // Could you explain to others?
    known_gaps?: string[];          // What you still don't understand
  };

  // Learning effort
  effort: {
    processing_time: '5min' | '30min' | '2hr' | 'days';
    cognitive_load: 'easy' | 'moderate' | 'hard' | 'breakthrough';
  };

  // Emotional context
  resonance: {
    intensity: number;              // 1-10: How much this hit you
    valence: 'positive' | 'negative' | 'mixed';
  };

  // Learning classification
  learning_type?: 'principle' | 'method' | 'anti_pattern' | 'exception';
  source_credit?: string;           // If from someone else

  // Metadata
  learningId: string;
  createdAt: Date;
  embedding: Float32Array;
}
```

## Key Design Principles

### 1. Intellectual Honesty Over Completeness

The schema **demands** honesty about understanding:
- Low confidence? Say it.
- Can't teach it? Mark false.
- Know what you don't know? List the gaps.

**Anti-pattern**: Marking everything confidence=9 and can_teach_it=true
**Good practice**: confidence=6, can_teach_it=false, known_gaps=["How this scales", "Edge cases"]

### 2. Abstraction Ladder (Concrete → Pattern → Principle)

Every learning should climb the abstraction ladder:

**Example: NestJS Performance**
- **Concrete**: "Our request-scoped logger caused API latency to jump from 50ms to 500ms"
- **Pattern**: "Dependency injection scope cascades through the entire dependency tree"
- **Principle**: "Isolation guarantees have multiplicative performance costs in hierarchical systems"

**Not every learning reaches "principle"** - and that's okay. Better to stop at pattern than to fabricate universal truths.

### 3. Structure Enables Retrieval

Breaking content into context/insight/why/implications enables:
- Better embedding quality (structured text)
- Targeted search ("find learnings where the WHY involves X")
- Quality filtering ("show me high-confidence learnings")
- Type filtering ("show me only anti-patterns")

### 4. Simplicity in Storage, Richness in Structure

Instead of normalizing every nested object into separate tables:
- Store nested objects (abstraction, understanding, effort, resonance) as **JSON TEXT**
- Only index fields used for filtering (learning_type, created_at)
- Simpler schema, easier to evolve, good enough for expected data volume

## Database Schema

### Simplified Approach: JSON Storage

```sql
CREATE TABLE learnings (
  learning_id TEXT PRIMARY KEY,

  -- Core fields
  title TEXT NOT NULL,
  context TEXT NOT NULL,
  insight TEXT NOT NULL,
  why TEXT NOT NULL,
  implications TEXT NOT NULL,
  tags TEXT NOT NULL,              -- JSON array: ["tag1", "tag2"]

  -- Nested objects stored as JSON
  abstraction TEXT NOT NULL,       -- JSON: {concrete, pattern, principle?}
  understanding TEXT NOT NULL,     -- JSON: {confidence, can_teach_it, known_gaps?}
  effort TEXT NOT NULL,            -- JSON: {processing_time, cognitive_load}
  resonance TEXT NOT NULL,         -- JSON: {intensity, valence}

  -- Classification
  learning_type TEXT,              -- 'principle' | 'method' | 'anti_pattern' | 'exception'
  source_credit TEXT,

  -- Vector embedding
  embedding BLOB NOT NULL,

  -- Timestamps
  created_at DATETIME NOT NULL,

  -- Indexes for common queries
  CHECK (learning_type IN ('principle', 'method', 'anti_pattern', 'exception', NULL))
);

CREATE INDEX idx_learnings_created ON learnings(created_at);
CREATE INDEX idx_learnings_type ON learnings(learning_type);
```

### Rationale for JSON Storage

**Pros:**
- Simple schema evolution (add fields to JSON without migrations)
- No JOIN complexity for nested objects
- Fast writes (single INSERT)
- Good enough for expected data volume (<10k learnings)

**Cons:**
- Can't query nested fields efficiently (e.g., "WHERE confidence > 7")
- JSON parsing overhead on reads
- No database-level validation of nested structure

**Verdict**: For this use case (personal knowledge base, < 10k learnings, primary access via semantic search), JSON storage is the pragmatic choice.

### Migration from Old Schema

Old schema tables will be **archived** with prefix `_archived_`:
- `_archived_learnings`
- `_archived_learning_categories`
- `_archived_learning_category_assignments`
- `_archived_learning_sources`

**No backfill** - fresh start with new schema. Old learnings remain queryable in archived tables if needed.

## Extraction Prompt

### Prompt Structure

The extraction prompt follows this structure:

1. **Task description**: "Extract learning moments from this conversation..."
2. **Field-by-field guidance**: What each field means, with examples
3. **Critical standards**: What to reject (shallow insights, buzzwords, feel-good revelations)
4. **Evidence of understanding**: Questions to ask yourself (Can you predict? Can you explain? Can you generate examples?)
5. **Output format**: JSON array structure
6. **Examples**: 5 diverse, high-quality learning examples

### Full Prompt (Abbreviated)

```
Extract learning moments from this conversation using the schema below.
Be intellectually honest and critical in your assessment.

Core Fields (Required):
- Context: What triggered this learning?
- Insight: The actual discovery. Be specific and concrete.
- Why: Your explanation of WHY this is true. Explain the mechanism.
- Implications: Concrete applications. Not vague "this is important" but "when X, do Y"

Abstraction Ladder:
- Concrete: The specific instance
- Pattern: The generalizable pattern
- Principle: Universal truth (optional - only if truly applies broadly)

Understanding Assessment (BE RUTHLESSLY HONEST):
- Confidence (1-10): How well do you understand this?
  1-3: Mostly guessing
  4-6: Get the basics but missing nuance
  7-8: Solid understanding with minor gaps
  9-10: Deep, complete understanding
- Can teach it: Would you be comfortable explaining this to a colleague?
- Known gaps: What specifically don't you understand?

Effort Tracking:
- Processing time: How long to reach this understanding?
- Cognitive load: easy/moderate/hard/breakthrough

Emotional Resonance:
- Intensity (1-10): How much did this affect you?
- Valence: positive/negative/mixed

Learning Type:
- principle: General truth or pattern
- method: Way of doing something
- anti_pattern: What NOT to do
- exception: Where a usual pattern doesn't apply

Critical Standards - REJECT:
- "X is important" without explaining why
- Buzzword soup without concrete understanding
- Feel-good revelations without actionable implications
- Claims you can teach something you've never taught

Output: JSON array. If no learnings, return [].

[5 detailed examples included in actual prompt]
```

See `notes.md` for the complete extraction prompt with all examples.

## Implementation Components

### 1. Core Types (`src/core/types.ts`)

```typescript
// Learning schema
interface Learning {
  learningId: string;
  title: string;
  context: string;
  insight: string;
  why: string;
  implications: string;
  tags: string[];
  abstraction: Abstraction;
  understanding: Understanding;
  effort: Effort;
  resonance: Resonance;
  learningType?: LearningType;
  sourceCredit?: string;
  createdAt: Date;
  embedding: Float32Array;
}

// Nested types
interface Abstraction {
  concrete: string;
  pattern: string;
  principle?: string;
}

interface Understanding {
  confidence: number;          // 1-10
  canTeachIt: boolean;
  knownGaps?: string[];
}

interface Effort {
  processingTime: '5min' | '30min' | '2hr' | 'days';
  cognitiveLoad: 'easy' | 'moderate' | 'hard' | 'breakthrough';
}

interface Resonance {
  intensity: number;           // 1-10
  valence: 'positive' | 'negative' | 'mixed';
}

type LearningType = 'principle' | 'method' | 'anti_pattern' | 'exception';

// Service interfaces remain unchanged
interface LearningExtractor {
  extract(conversationId: string): Promise<Learning[]>;
}

interface LearningSearch {
  search(query: string, options?: SearchOptions): Promise<LearningSearchResult[]>;
}
```

### 2. Extraction Service (`src/services/learning-extraction.ts`)

```typescript
class LearningExtractionImpl implements LearningExtractor {
  constructor(
    private llmModel: LLMModel,
    private db: Database,
    private vectorStore: VectorStore,
    private embeddingModel: EmbeddingModel
  ) {}

  async extract(conversationId: string): Promise<Learning[]> {
    // 1. Fetch conversation messages
    const messages = this.fetchConversationMessages(conversationId);

    // 2. Build extraction prompt (from notes.md)
    const prompt = this.buildExtractionPrompt(messages);

    // 3. Call LLM with structured output
    const response = await this.llmModel.generate(prompt);

    // 4. Parse JSON response into Learning[]
    const learnings = this.parseExtractionResponse(response);

    // 5. Generate embeddings (concatenate all searchable fields)
    const textsToEmbed = learnings.map(l =>
      `${l.title} ${l.context} ${l.insight} ${l.why} ${l.implications} ${l.abstraction.concrete} ${l.abstraction.pattern} ${l.abstraction.principle || ''}`
    );
    const embeddings = await this.embeddingModel.embedBatch(textsToEmbed);

    // 6. Store in database + vector store
    await this.vectorStore.storeLearnings(learnings, embeddings);

    return learnings;
  }

  private buildExtractionPrompt(messages: Message[]): string {
    // Load full prompt from notes.md
    // Append conversation messages
    // Return complete prompt
  }

  private parseExtractionResponse(response: string): Learning[] {
    // Parse JSON array
    // Validate structure
    // Generate UUIDs
    // Set createdAt timestamps
    // Return Learning[]
  }
}
```

### 3. Vector Store (`src/db/vector-store.ts`)

```typescript
class SqliteVectorStore {
  storeLearnings(learnings: Learning[], embeddings: Float32Array[]): void {
    const stmt = this.db.prepare(`
      INSERT INTO learnings (
        learning_id, title, context, insight, why, implications, tags,
        abstraction, understanding, effort, resonance,
        learning_type, source_credit, embedding, created_at
      ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    `);

    const insertMany = this.db.transaction(() => {
      learnings.forEach((learning, i) => {
        stmt.run(
          learning.learningId,
          learning.title,
          learning.context,
          learning.insight,
          learning.why,
          learning.implications,
          JSON.stringify(learning.tags),
          JSON.stringify(learning.abstraction),
          JSON.stringify(learning.understanding),
          JSON.stringify(learning.effort),
          JSON.stringify(learning.resonance),
          learning.learningType || null,
          learning.sourceCredit || null,
          Buffer.from(embeddings[i].buffer),
          learning.createdAt.toISOString()
        );
      });
    });

    insertMany();
  }

  searchLearnings(query: string, options?: SearchOptions): Learning[] {
    // Semantic search unchanged (still uses cosine similarity)
    // Parse JSON fields when reconstructing Learning objects
    const rows = this.db.prepare(`
      SELECT * FROM learnings
      WHERE /* vector search conditions */
    `).all();

    return rows.map(row => ({
      learningId: row.learning_id,
      title: row.title,
      context: row.context,
      insight: row.insight,
      why: row.why,
      implications: row.implications,
      tags: JSON.parse(row.tags),
      abstraction: JSON.parse(row.abstraction),
      understanding: JSON.parse(row.understanding),
      effort: JSON.parse(row.effort),
      resonance: JSON.parse(row.resonance),
      learningType: row.learning_type,
      sourceCredit: row.source_credit,
      createdAt: new Date(row.created_at),
      embedding: new Float32Array(row.embedding.buffer)
    }));
  }
}
```

### 4. Search Service (`src/services/learning-search.ts`)

```typescript
class LearningSearchImpl implements LearningSearch {
  async search(query: string, options?: SearchOptions): Promise<LearningSearchResult[]> {
    // 1. Generate query embedding
    const queryEmbedding = await this.embeddingModel.embed(query);

    // 2. Vector search (unchanged)
    const learnings = await this.vectorStore.searchLearnings(query, options);

    // 3. Optional filtering by tags (replaces category filtering)
    if (options?.tags) {
      learnings = learnings.filter(l =>
        options.tags.some(tag => l.tags.includes(tag))
      );
    }

    // 4. Optional filtering by learning type
    if (options?.learningType) {
      learnings = learnings.filter(l => l.learningType === options.learningType);
    }

    return learnings;
  }
}
```

### 5. CLI Commands

#### Extract Learnings (`src/cli/extract-learnings.ts`)

Minimal changes - extraction logic is in service layer.

```typescript
program
  .name('extract-learnings')
  .description('Extract learnings from conversations')
  .action(async () => {
    const extractor = createLearningExtractor(config);
    const learnings = await extractor.extract(conversationId);
    console.log(`✓ Extracted ${learnings.length} learnings`);
  });
```

#### Search Learnings (`src/cli/search-learnings.ts`)

Updated for **summary view** display:

```typescript
program
  .name('search-learnings')
  .description('Search for learnings')
  .argument('<query>', 'Search query')
  .option('--tags <tags>', 'Filter by tags (comma-separated)')
  .option('--type <type>', 'Filter by learning type')
  .option('--detailed', 'Show detailed view instead of summary')
  .action(async (query, options) => {
    const search = createLearningSearch(config);
    const results = await search.search(query, {
      tags: options.tags?.split(','),
      learningType: options.type
    });

    results.forEach(result => {
      if (options.detailed) {
        displayDetailedLearning(result);
      } else {
        displaySummaryLearning(result);
      }
    });
  });

function displaySummaryLearning(learning: Learning): void {
  console.log(`\n[${learning.tags.join(', ')}] ${learning.title}`);

  // Show principle if available, fallback to pattern
  const abstraction = learning.abstraction.principle || learning.abstraction.pattern;
  console.log(`  → ${abstraction}`);

  // Show type if present
  if (learning.learningType) {
    console.log(`  Type: ${learning.learningType}`);
  }
}

function displayDetailedLearning(learning: Learning): void {
  console.log(`\n${'='.repeat(80)}`);
  console.log(`[${learning.tags.join(', ')}] ${learning.title}\n`);
  console.log(`Context: ${learning.context}\n`);
  console.log(`Insight: ${learning.insight}\n`);
  console.log(`Why: ${learning.why}\n`);
  console.log(`Implications: ${learning.implications}\n`);
  console.log(`Abstraction:`);
  console.log(`  Concrete: ${learning.abstraction.concrete}`);
  console.log(`  Pattern: ${learning.abstraction.pattern}`);
  if (learning.abstraction.principle) {
    console.log(`  Principle: ${learning.abstraction.principle}`);
  }
  console.log(`\nUnderstanding:`);
  console.log(`  Confidence: ${learning.understanding.confidence}/10`);
  console.log(`  Can teach it: ${learning.understanding.canTeachIt ? 'Yes' : 'No'}`);
  if (learning.understanding.knownGaps?.length) {
    console.log(`  Known gaps: ${learning.understanding.knownGaps.join(', ')}`);
  }
  console.log(`\nEffort:`);
  console.log(`  Processing time: ${learning.effort.processingTime}`);
  console.log(`  Cognitive load: ${learning.effort.cognitiveLoad}`);
  console.log(`\nResonance:`);
  console.log(`  Intensity: ${learning.resonance.intensity}/10`);
  console.log(`  Valence: ${learning.resonance.valence}`);

  if (learning.learningType) {
    console.log(`\nType: ${learning.learningType}`);
  }
  if (learning.sourceCredit) {
    console.log(`Source: ${learning.sourceCredit}`);
  }
  console.log(`\nCreated: ${learning.createdAt.toLocaleString()}`);
}
```

#### Markdown Diary Generation

Summary view for diary:

```markdown
# Learning Diary

## 2024-01-15

### [software-architecture, nestjs] Request-scoped providers tank NestJS performance
→ Isolation guarantees have multiplicative performance costs in hierarchical systems
Type: anti_pattern

### [music, rhythm] Four Tet's floating feeling comes from polyrhythm
→ Violated expectations at regular intervals create aesthetic pleasure
Type: principle

## 2024-01-14

...
```

With `--detailed` flag, expands to full schema.

## Quality Considerations

### Known Limitations (Accepted Trade-offs)

The schema includes fields that **cannot be reliably extracted** from conversation text:

1. **Processing time**: Conversations don't have timestamps for "aha moments"
   - LLM will guess based on conversation length
   - Accept: Approximate values, useful for rough filtering

2. **Can teach it**: Teaching ability isn't evident from passive understanding
   - LLM will infer from explanation quality
   - Accept: Optimistic assessments, treat as "appears to understand"

3. **Known gaps**: Requires detecting what's NOT discussed
   - LLM will often leave empty or hallucinate plausible gaps
   - Accept: Incomplete, best-effort detection

4. **Emotional resonance**: Inference from text without explicit emotional markers
   - LLM will look for intensity markers ("wow", "fascinating", "frustrating")
   - Accept: Reliable only when emotions are explicitly expressed

5. **Confidence**: Requires metacognitive awareness not always present
   - LLM will infer from hedging language, questions asked, depth of explanation
   - Accept: Proxy for apparent confidence, not true self-assessment

**Philosophy**: These fields represent an **aspirational framework** for learning capture. Even with imperfect extraction, they provide:
- Structure for thinking about learning quality
- Rough filters for browsing ("show me breakthroughs")
- Prompts for manual reflection ("Do I really understand this?")

### Extraction Quality Assurance

To maintain extraction quality:

1. **Prompt engineering**: Detailed examples showing high-quality vs. low-quality extractions
2. **Critical standards**: Explicit rejection criteria in prompt
3. **Manual review**: Sample 10-20 extractions, refine prompt based on patterns
4. **Iterative refinement**: Track which fields are consistently empty/low-quality

### When to Use Detailed View

**Summary view** (default):
- Browsing/scanning many learnings
- Quick search to find relevant learning
- Diary review (daily/weekly)

**Detailed view** (`--detailed` flag):
- Deep review of specific learning
- Understanding abstraction ladder
- Assessing confidence/gaps
- Analyzing learning patterns (effort, resonance)

## Integration with Existing System

### What Changes

1. **Learning schema**: Completely replaced (4 fields → 15+ fields)
2. **Database schema**: Simplified (JSON storage, no category tables)
3. **Extraction prompt**: Completely rewritten (from basic to epistemic framework)
4. **CLI output**: Summary view by default, detailed optional
5. **Diary format**: Condensed to title + principle + tags

### What Stays the Same

1. **Service interfaces**: `LearningExtractor` and `LearningSearch` signatures unchanged
2. **Factory pattern**: DI wiring unchanged
3. **Semantic search**: Still uses embeddings + cosine similarity
4. **Conversation ingestion**: Unaffected (upstream of learning extraction)
5. **Vector store implementation**: Core search logic unchanged

### Removed Features

1. **Structured categories**: Replaced with free-form tags
2. **Category management**: No more `learning_categories` table
3. **Source relationships**: No more `learning_sources` table (replaced with `source_credit` string)

**Rationale**: Structured categories were over-engineered for the use case. Free-form tags provide same organizational benefits with less complexity.

## Testing Strategy

### Unit Tests

Update mock Learning data:

```typescript
const mockLearning: Learning = {
  learningId: 'test-123',
  title: 'Test Learning',
  context: 'Test context',
  insight: 'Test insight',
  why: 'Test explanation',
  implications: 'Test applications',
  tags: ['test', 'mock'],
  abstraction: {
    concrete: 'Test concrete example',
    pattern: 'Test pattern',
    principle: 'Test principle'
  },
  understanding: {
    confidence: 7,
    canTeachIt: true,
    knownGaps: ['Test gap']
  },
  effort: {
    processingTime: '30min',
    cognitiveLoad: 'moderate'
  },
  resonance: {
    intensity: 6,
    valence: 'positive'
  },
  learningType: 'principle',
  sourceCredit: undefined,
  createdAt: new Date(),
  embedding: new Float32Array(768)
};
```

### Integration Tests

Test full extraction flow with real database:

```typescript
it('should extract learnings with full schema', async () => {
  const conversationId = 'test-conversation';
  const learnings = await extractor.extract(conversationId);

  expect(learnings.length).toBeGreaterThan(0);

  learnings.forEach(learning => {
    expect(learning.title).toBeTruthy();
    expect(learning.context).toBeTruthy();
    expect(learning.insight).toBeTruthy();
    expect(learning.why).toBeTruthy();
    expect(learning.abstraction.concrete).toBeTruthy();
    expect(learning.abstraction.pattern).toBeTruthy();
    expect(learning.understanding.confidence).toBeGreaterThanOrEqual(1);
    expect(learning.understanding.confidence).toBeLessThanOrEqual(10);
  });
});
```

### E2E Tests

Test CLI commands with new output format:

```typescript
it('should display summary view by default', async () => {
  const output = await execCommand('search-learnings "test query"');

  expect(output).toContain('[tag1, tag2]');
  expect(output).toContain('→'); // Principle separator
  expect(output).not.toContain('Context:'); // Not detailed view
});

it('should display detailed view with flag', async () => {
  const output = await execCommand('search-learnings "test query" --detailed');

  expect(output).toContain('Context:');
  expect(output).toContain('Insight:');
  expect(output).toContain('Abstraction:');
  expect(output).toContain('Understanding:');
});
```

## Migration Checklist

### Phase 1: Schema & Types
- [ ] Update `Learning` interface in `src/core/types.ts`
- [ ] Add nested type definitions (Abstraction, Understanding, Effort, Resonance)
- [ ] Update `src/db/schema.ts` with new table definition
- [ ] Archive old tables with `_archived_` prefix
- [ ] Run schema migration

### Phase 2: Extraction
- [ ] Update extraction prompt in `src/services/learning-extraction.ts`
- [ ] Update JSON parsing for new schema
- [ ] Update embedding generation (concatenate all searchable fields)
- [ ] Test extraction on 20 conversations

### Phase 3: Storage & Search
- [ ] Update `storeLearnings()` in vector store for JSON serialization
- [ ] Update `searchLearnings()` for JSON deserialization
- [ ] Remove category filtering, add tag filtering
- [ ] Add learning type filtering

### Phase 4: CLI & Display
- [ ] Implement `displaySummaryLearning()` function
- [ ] Implement `displayDetailedLearning()` function
- [ ] Add `--detailed` flag to search command
- [ ] Update diary generation for summary view
- [ ] Add `--detailed` flag to diary command

### Phase 5: Testing
- [ ] Update all mock Learning objects
- [ ] Update unit tests for new schema
- [ ] Update integration tests
- [ ] Update E2E tests
- [ ] Run `npm test` - all tests pass

### Phase 6: Documentation
- [ ] Create this document (docs/2. ADVANCED LEARNINGS SCHEMA.md)
- [ ] Update README if needed
- [ ] Document known limitations in extraction quality

## Success Metrics

After implementation, evaluate:

1. **Extraction quality**: Review 50 extracted learnings
   - Are abstraction ladders well-formed?
   - Are confidence scores plausible?
   - Are known gaps actually gaps?

2. **Display usability**: Can you scan 20 learnings quickly?
   - Is summary view concise enough?
   - Is detailed view too verbose?
   - Is diary format still readable?

3. **Search utility**: Do additional filters help?
   - Tag filtering usage
   - Learning type filtering usage
   - Confidence/intensity filtering (if added)

4. **Schema evolution**: Any fields consistently empty?
   - Consider removing or making truly optional
   - Consider adding fields users want

## Future Enhancements (Out of Scope)

Possible future additions:

1. **User annotations**: CLI command to manually adjust confidence/gaps/resonance after extraction
2. **Spaced repetition**: Test yourself on learnings, update confidence based on recall
3. **Learning connections**: Graph of related learnings (shared patterns/principles)
4. **Quality filtering**: Filter by confidence/intensity thresholds
5. **Learning analytics**: Dashboard of learning patterns over time
6. **Multi-source extraction**: Not just conversations, but articles, books, videos

## References

- Original proposal: `notes.md`
- Current implementation: `docs/1. LEARNINGS.md`
- Critical review: Agent analysis (2024-01-15)
